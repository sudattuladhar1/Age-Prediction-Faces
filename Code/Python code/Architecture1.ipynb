{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T14:57:20.168081Z",
     "iopub.status.busy": "2022-05-03T14:57:20.167491Z",
     "iopub.status.idle": "2022-05-03T14:57:21.711555Z",
     "shell.execute_reply": "2022-05-03T14:57:21.710757Z",
     "shell.execute_reply.started": "2022-05-03T14:57:20.167981Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T14:57:21.71319Z",
     "iopub.status.busy": "2022-05-03T14:57:21.71297Z",
     "iopub.status.idle": "2022-05-03T14:57:21.721461Z",
     "shell.execute_reply": "2022-05-03T14:57:21.720375Z",
     "shell.execute_reply.started": "2022-05-03T14:57:21.713166Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input image reading and loading using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T14:57:21.723912Z",
     "iopub.status.busy": "2022-05-03T14:57:21.723395Z",
     "iopub.status.idle": "2022-05-03T14:57:21.734035Z",
     "shell.execute_reply": "2022-05-03T14:57:21.733036Z",
     "shell.execute_reply.started": "2022-05-03T14:57:21.723859Z"
    }
   },
   "outputs": [],
   "source": [
    "class Imageread(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.df = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['filename'])\n",
    "        image = read_image(img_path)/255.0\n",
    "        label = self.df.iloc[idx]['age']/100.0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T14:57:21.736448Z",
     "iopub.status.busy": "2022-05-03T14:57:21.735961Z",
     "iopub.status.idle": "2022-05-03T14:57:21.745311Z",
     "shell.execute_reply": "2022-05-03T14:57:21.744655Z",
     "shell.execute_reply.started": "2022-05-03T14:57:21.736411Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = \"project2-data-80k-10k-10k\"\n",
    "#dataset_name = \"sample-dataset-project2\"\n",
    "\n",
    "train_csv = f'../input/{dataset_name}/Data_train.csv'\n",
    "val_csv = f'../input/{dataset_name}/Data_validation.csv'\n",
    "test_csv = f'../input/{dataset_name}/Data_test.csv'\n",
    "train_data = f'../input/{dataset_name}/Training_data'\n",
    "val_data = f'../input/{dataset_name}/Validation_data'\n",
    "test_data = f'../input/{dataset_name}/Testing_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T14:57:21.7473Z",
     "iopub.status.busy": "2022-05-03T14:57:21.746811Z",
     "iopub.status.idle": "2022-05-03T14:57:22.000396Z",
     "shell.execute_reply": "2022-05-03T14:57:21.999229Z",
     "shell.execute_reply.started": "2022-05-03T14:57:21.747254Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data_transform = transforms.Compose([\n",
    "#     transforms.Normalize(mean = (0.445,), std = (0.269,))\n",
    "# ])\n",
    "\n",
    "training_data = Imageread(train_csv, train_data, transform=None, target_transform=None)\n",
    "train_dataloader = DataLoader(training_data, batch_size=100, shuffle=True, num_workers = 2)\n",
    "\n",
    "validation_data = Imageread(val_csv, val_data, transform=None, target_transform=None)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=100, shuffle=True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T14:57:22.002371Z",
     "iopub.status.busy": "2022-05-03T14:57:22.002147Z",
     "iopub.status.idle": "2022-05-03T14:57:22.811346Z",
     "shell.execute_reply": "2022-05-03T14:57:22.810417Z",
     "shell.execute_reply.started": "2022-05-03T14:57:22.002345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Architecture Model\n",
    "#model = \n",
    "# model = nn.Sequential(\n",
    "#            nn.Conv2d(1, 64, kernel_size=5),\n",
    "#            nn.ReLU(),\n",
    "#            #nn.AvgPool2d(2),\n",
    "#            nn.MaxPool2d(2,2),\n",
    "#            nn.Conv2d(64,128, kernel_size=5),\n",
    "#            nn.ReLU(),\n",
    "#            nn.MaxPool2d(2,2),\n",
    "#            #nn.AvgPool2d(2),\n",
    "#            nn.Flatten(),\n",
    "#            nn.Linear(128*13*13,4096),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(4096, 1),\n",
    "#          )\n",
    "model = nn.Sequential(\n",
    "           nn.Conv2d(1, 64, kernel_size=5),\n",
    "           nn.BatchNorm2d(64),\n",
    "           nn.ReLU(),\n",
    "           nn.MaxPool2d(2,2),\n",
    "           nn.Dropout(0.5),\n",
    "    \n",
    "           nn.Conv2d(64,128, kernel_size=5),\n",
    "           nn.BatchNorm2d(128),\n",
    "           nn.ReLU(),\n",
    "           nn.MaxPool2d(2,2),\n",
    "           nn.Dropout(0.5),\n",
    "          \n",
    "           nn.Flatten(),\n",
    "           nn.Linear(128*13*13,4096),\n",
    "           nn.BatchNorm1d(4096),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(4096, 1),\n",
    "         )\n",
    "\n",
    "net = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T14:57:22.812583Z",
     "iopub.status.busy": "2022-05-03T14:57:22.812381Z",
     "iopub.status.idle": "2022-05-03T14:57:23.065154Z",
     "shell.execute_reply": "2022-05-03T14:57:23.064082Z",
     "shell.execute_reply.started": "2022-05-03T14:57:22.812559Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_epoch = 25\n",
    "validation_loss = np.zeros(NUM_epoch)\n",
    "training_loss = np.zeros(NUM_epoch)\n",
    "\n",
    "for epoch in range(NUM_epoch):\n",
    "    #print(f\"epoch: {epoch}\")\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    train_len = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().view(-1,1).to(device)\n",
    "        train_len = train_len + 1\n",
    "        \n",
    "        # Model computation\n",
    "        outputs = net(inputs)\n",
    "        #print('inputs:', inputs)\n",
    "#         print('outputs',torch.transpose(outputs,0,1))\n",
    "#         print('labels',labels)\n",
    "        loss = criterion(outputs, labels) #calculating the predicted and the expected loss \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #compute the gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    training_loss[epoch] = train_loss/train_len\n",
    "#     print('outputs',torch.transpose(outputs,0,1))\n",
    "#     print('labels',labels)\n",
    "    \n",
    "    #validation\n",
    "    with torch.no_grad():\n",
    "        val_len=0\n",
    "        val_loss = 0.0\n",
    "        for inputs, labels in validation_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().view(-1,1).to(device)\n",
    "            val_len = val_len + 1\n",
    "           \n",
    "            # Model computation\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels) #calculating the predicted and the expected loss\n",
    "\n",
    "            val_loss += loss.item()\n",
    "        validation_loss[epoch] = val_loss/val_len\n",
    "    print(f\"epoch: {epoch}, train_loss: {training_loss[epoch]:.6f}, validation_loss: {validation_loss[epoch]:.6f}\")\n",
    "    if epoch>1 and np.abs(validation_loss[epoch]-validation_loss[epoch-1])<10**(-5):\n",
    "        print('validation loss converges')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:42:40.110203Z",
     "iopub.status.busy": "2022-05-02T16:42:40.109926Z",
     "iopub.status.idle": "2022-05-02T16:42:40.423838Z",
     "shell.execute_reply": "2022-05-02T16:42:40.423152Z",
     "shell.execute_reply.started": "2022-05-02T16:42:40.110158Z"
    }
   },
   "outputs": [],
   "source": [
    "#saving and plotting the loss values\n",
    "df = pd.DataFrame({\n",
    "    'epoch':range(epoch+1),\n",
    "    'training_loss':training_loss[0:epoch+1],\n",
    "    'validation_loss':validation_loss[0:epoch+1]\n",
    "})\n",
    "df\n",
    "ax= df.iloc[0:].plot(y=['training_loss','validation_loss'],figsize= (12,6),xticks=df.index, fontsize=15,marker ='o', rot = 45)\n",
    "ax.set_ylabel('loss',fontsize=15)\n",
    "ax.set_xlabel('Epoch',fontsize=15)\n",
    "plt.savefig('loss.jpg')\n",
    "plt.show()\n",
    "df.to_csv('loss.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:42:40.425345Z",
     "iopub.status.busy": "2022-05-02T16:42:40.425078Z",
     "iopub.status.idle": "2022-05-02T16:42:40.44918Z",
     "shell.execute_reply": "2022-05-02T16:42:40.448495Z",
     "shell.execute_reply.started": "2022-05-02T16:42:40.425307Z"
    }
   },
   "outputs": [],
   "source": [
    "testdata = Imageread(test_csv, test_data, transform=None, target_transform=None)\n",
    "test_dataloader = DataLoader(testdata, batch_size=100, shuffle=False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:42:40.450828Z",
     "iopub.status.busy": "2022-05-02T16:42:40.450511Z",
     "iopub.status.idle": "2022-05-02T16:42:50.171399Z",
     "shell.execute_reply": "2022-05-02T16:42:50.170507Z",
     "shell.execute_reply.started": "2022-05-02T16:42:40.450775Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_len=0\n",
    "    test_loss=0.0\n",
    "    outputs_array = np.array([])\n",
    "    labels_array = np.array([])\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().view(-1, 1).to(device)\n",
    "        test_len = test_len + 1\n",
    "        #labels = labels.type(torch.FloatTensor)\n",
    "        # Model computation\n",
    "        outputs = net(inputs)\n",
    "        outputs_array = np.append(outputs_array,outputs.detach().cpu().numpy())\n",
    "        labels_array = np.append(labels_array,labels.cpu())\n",
    "    #     print('output:', torch.transpose(outputs,0,1))\n",
    "    #     print('labels:', labels)\n",
    "        loss = criterion(outputs, labels) #calculating the predicted and the expected loss\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    print(test_loss/test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:42:50.173434Z",
     "iopub.status.busy": "2022-05-02T16:42:50.173157Z",
     "iopub.status.idle": "2022-05-02T16:43:02.494298Z",
     "shell.execute_reply": "2022-05-02T16:43:02.493626Z",
     "shell.execute_reply.started": "2022-05-02T16:42:50.173396Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({\n",
    "    'true_age':np.round(labels_array*100,1),\n",
    "    'predict_age': np.round(outputs_array*100,1),\n",
    "})\n",
    "ax = df_test.plot(y=['true_age','predict_age'],figsize= (12,6),xticks=df_test.index, fontsize=15,marker ='o', rot = 45)\n",
    "ax.set_ylabel('Age', fontsize = 16)\n",
    "ax.set_xticks([])\n",
    "plt.savefig('test.jpg')\n",
    "\n",
    "df_test.to_csv('Test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:43:02.497951Z",
     "iopub.status.busy": "2022-05-02T16:43:02.495525Z",
     "iopub.status.idle": "2022-05-02T16:43:02.50614Z",
     "shell.execute_reply": "2022-05-02T16:43:02.505216Z",
     "shell.execute_reply.started": "2022-05-02T16:43:02.49791Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:43:02.516637Z",
     "iopub.status.busy": "2022-05-02T16:43:02.516395Z",
     "iopub.status.idle": "2022-05-02T16:43:02.524813Z",
     "shell.execute_reply": "2022-05-02T16:43:02.524087Z",
     "shell.execute_reply.started": "2022-05-02T16:43:02.516604Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:43:02.527918Z",
     "iopub.status.busy": "2022-05-02T16:43:02.525742Z",
     "iopub.status.idle": "2022-05-02T16:43:02.533711Z",
     "shell.execute_reply": "2022-05-02T16:43:02.532953Z",
     "shell.execute_reply.started": "2022-05-02T16:43:02.52788Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img #.int()#*255     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:43:02.537051Z",
     "iopub.status.busy": "2022-05-02T16:43:02.536467Z",
     "iopub.status.idle": "2022-05-02T16:43:02.726424Z",
     "shell.execute_reply": "2022-05-02T16:43:02.725668Z",
     "shell.execute_reply.started": "2022-05-02T16:43:02.537012Z"
    }
   },
   "outputs": [],
   "source": [
    "testdata = Imageread(test_csv, test_data, transform=None, target_transform=None)\n",
    "test_dataloader = DataLoader(testdata, batch_size=8, shuffle=True)\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        imshow(torchvision.utils.make_grid(inputs))\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().view(-1, 1).numpy()\n",
    "\n",
    "        # Model computation\n",
    "        outputs=net(inputs)\n",
    "\n",
    "\n",
    "        print('True Age   : ', end = '')\n",
    "        print(' '.join(f'{labels[j][0]*100:.2f},' for j in range(8)))\n",
    "        print('Predict Age: ', end = '')\n",
    "        print(' '.join(f'{outputs[j][0]*100:.2f},' for j in range(8)))\n",
    "        break\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:43:02.728467Z",
     "iopub.status.busy": "2022-05-02T16:43:02.728024Z",
     "iopub.status.idle": "2022-05-02T16:43:03.900204Z",
     "shell.execute_reply": "2022-05-02T16:43:03.899139Z",
     "shell.execute_reply.started": "2022-05-02T16:43:02.728428Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'net_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T16:43:03.907842Z",
     "iopub.status.busy": "2022-05-02T16:43:03.905314Z",
     "iopub.status.idle": "2022-05-02T16:43:04.125726Z",
     "shell.execute_reply": "2022-05-02T16:43:04.125069Z",
     "shell.execute_reply.started": "2022-05-02T16:43:03.90774Z"
    }
   },
   "outputs": [],
   "source": [
    "start = np.random.randint(0, 500)\n",
    "ax = df_test.iloc[start:start+100].plot(y=['true_age','predict_age'],figsize= (12,6),fontsize=15,marker ='o', rot = 45)\n",
    "ax.set_ylabel('Age', fontsize = 16)\n",
    "ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
